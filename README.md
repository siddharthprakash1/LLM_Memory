# ğŸ§  LLM Memory

<div align="center">

![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-production--ready-brightgreen.svg)

**Hierarchical Long-Term Memory for LLM Agents**

*Real memory with decay, consolidation, conflict resolution, and intent-aware retrieval*

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Quick Start](#-quick-start) â€¢ [Architecture](#-architecture) â€¢ [Benchmarks](#-benchmarks) â€¢ [API Reference](#-api-reference)

</div>

---

## ğŸ¯ What is LLM Memory?

LLM Memory is a **production-grade cognitive memory system** for AI agents. Unlike simple context windows or basic RAG, it implements a biologically-inspired memory architecture with:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ğŸ§  LLM MEMORY SYSTEM                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   ğŸ“¥ INPUT                    ğŸ”„ PROCESSING              ğŸ“¤ OUTPUT      â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€â”€â”€â”€â”€â”€       â”‚
â”‚                                                                         â”‚
â”‚   "Remember    â”€â”€â”€â”€â”€â”€â–º    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”€â”€â”€â”€â”€â”€â–º   Structured     â”‚
â”‚    my name                â”‚   Encoding   â”‚              Memory         â”‚
â”‚    is John"               â”‚  (Embedding) â”‚              Storage        â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                  â”‚                                      â”‚
â”‚                                  â–¼                                      â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                           â”‚   Memory     â”‚                             â”‚
â”‚   "What's     â—„â”€â”€â”€â”€â”€â”€     â”‚   Decay &    â”‚    â—„â”€â”€â”€â”€â”€â”€   Retrieval     â”‚
â”‚    my name?"              â”‚ Consolidationâ”‚              with RAG       â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                                         â”‚
â”‚   "Your name              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              Vector         â”‚
â”‚    is John"   â—„â”€â”€â”€â”€â”€â”€     â”‚   Conflict   â”‚    â—„â”€â”€â”€â”€â”€â”€   Search        â”‚
â”‚                           â”‚  Resolution  â”‚                             â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

### Memory Types

| Type | Description | Use Case | Retention |
|------|-------------|----------|-----------|
| ğŸ”´ **Short-Term** | Recent conversation context | Current session | Minutes to hours |
| ğŸŸ¡ **Episodic** | Specific events & experiences | "What happened when..." | Days to weeks |
| ğŸŸ¢ **Semantic** | Facts, concepts, relationships | "What is X?" | Long-term |

### Core Capabilities

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FEATURE MATRIX                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Feature             â”‚ Status        â”‚ Description                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Vector Search       â”‚ âœ… Production â”‚ ChromaDB + HNSW indexing    â”‚
â”‚ RAG Pipeline        â”‚ âœ… Production â”‚ LLM answer synthesis        â”‚
â”‚ Memory Decay        â”‚ âœ… Production â”‚ Ebbinghaus forgetting curve â”‚
â”‚ Consolidation       â”‚ âœ… Production â”‚ STM â†’ Episodic â†’ Semantic   â”‚
â”‚ Conflict Resolution â”‚ âœ… Production â”‚ 6 detection + 8 strategies  â”‚
â”‚ Multi-hop Reasoning â”‚ âœ… Production â”‚ Iterative retrieval         â”‚
â”‚ Temporal Logic      â”‚ âœ… Production â”‚ Time-aware scoring          â”‚
â”‚ Intent Classificationâ”‚ âœ… Production â”‚ Query understanding        â”‚
â”‚ LangChain Support   â”‚ âœ… Production â”‚ Full integration            â”‚
â”‚ Ollama Support      â”‚ âœ… Production â”‚ Local LLM inference         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.11+
- [Ollama](https://ollama.ai) (for local LLM)

### Quick Install

```bash
# Clone the repository
git clone https://github.com/siddharthprakash1/LLM_Memory.git
cd LLM_Memory

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -e ".[dev,langchain,agent,ui]"

# Pull required Ollama models
ollama pull gemma3:27b        # Main LLM (or any model you prefer)
ollama pull nomic-embed-text  # Embedding model
```

### Docker (Coming Soon)

```bash
docker pull llmmemory/llm-memory:latest
docker run -p 8000:8000 llmmemory/llm-memory
```

---

## ğŸš€ Quick Start

### Basic Usage

```python
import asyncio
from llm_memory import MemorySystem, MemoryConfig

async def main():
    # Initialize memory system
    memory = MemorySystem()
    await memory.initialize()
    await memory.start()
    
    # Store memories
    await memory.remember("My name is Alice", user_id="user_1")
    await memory.remember("I work at OpenAI as a researcher", user_id="user_1")
    await memory.remember("My favorite color is purple", user_id="user_1")
    
    # Recall memories
    results = await memory.recall("What is my name?", user_id="user_1")
    print(results)  # Returns relevant memories about Alice
    
    # Cleanup
    await memory.stop()

asyncio.run(main())
```

### With RAG Pipeline

```python
from llm_memory.retrieval import RAGPipeline, create_rag_pipeline

async def main():
    # Create RAG pipeline
    pipeline = await create_rag_pipeline(
        persist_directory="./memory_store",
        embed_func=your_embed_function,
        llm_func=your_llm_function,
    )
    
    # Get natural language answers
    result = await pipeline.answer("What does Alice do for work?")
    
    print(f"Answer: {result.answer}")
    print(f"Confidence: {result.confidence:.2f}")
    print(f"Sources: {len(result.sources)}")

asyncio.run(main())
```

### CLI Agent

```bash
# Run the memory-powered chat agent
python -m llm_memory.agent.cli

# Commands:
#   /help     - Show available commands
#   /memory   - View memory statistics
#   /remember - Store a memory
#   /recall   - Search memories
#   /new      - Start new session
#   /quit     - Exit
```

### Web UI

```bash
# Launch Gradio interface
python -m llm_memory.agent.web_ui

# Open http://localhost:7860 in your browser
```

---

## ğŸ— Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           LLM MEMORY ARCHITECTURE                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   User /    â”‚
                              â”‚   Agent     â”‚
                              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                â”‚                â”‚
                    â–¼                â–¼                â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Remember â”‚    â”‚   Recall  â”‚    â”‚   Forget  â”‚
            â”‚    API    â”‚    â”‚    API    â”‚    â”‚    API    â”‚
            â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                  â”‚                â”‚                â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          MEMORY SYSTEM ORCHESTRATOR                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         Processing Pipeline                              â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ Encoding â”‚â†’ â”‚  Intent  â”‚â†’ â”‚ Conflict â”‚â†’ â”‚ Storage  â”‚â†’ â”‚  Index   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚          â”‚  â”‚ Classify â”‚  â”‚  Check   â”‚  â”‚          â”‚  â”‚          â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         Retrieval Pipeline                               â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  Query   â”‚â†’ â”‚  Vector  â”‚â†’ â”‚ Temporal â”‚â†’ â”‚ Multi-   â”‚â†’ â”‚   RAG    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Embed   â”‚  â”‚  Search  â”‚  â”‚ Scoring  â”‚  â”‚   Hop    â”‚  â”‚ Synthesisâ”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                       Background Processes                               â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚ â”‚
â”‚  â”‚  â”‚    Memory    â”‚  â”‚  Garbage     â”‚  â”‚   Decay      â”‚                   â”‚ â”‚
â”‚  â”‚  â”‚ Consolidationâ”‚  â”‚  Collection  â”‚  â”‚   Updates    â”‚                   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚              â”‚              â”‚
                    â–¼              â–¼              â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  SQLite   â”‚  â”‚ ChromaDB  â”‚  â”‚   Event   â”‚
            â”‚ (Metadata)â”‚  â”‚ (Vectors) â”‚  â”‚   Hooks   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Hierarchy

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         WORKING MEMORY              â”‚
                    â”‚    (Active conversation context)    â”‚
                    â”‚         Capacity: ~10 items         â”‚
                    â”‚         Duration: Seconds           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   ATTENTION &   â”‚
                              â”‚   REHEARSAL     â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         SHORT-TERM MEMORY           â”‚
                    â”‚      (Recent interactions)          â”‚
                    â”‚      Capacity: ~100 items           â”‚
                    â”‚      Duration: Minutes-Hours        â”‚
                    â”‚      Decay: Fast exponential        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  CONSOLIDATION  â”‚
                              â”‚  (Sleep-like)   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                                                     â”‚
            â–¼                                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     EPISODIC MEMORY       â”‚               â”‚     SEMANTIC MEMORY       â”‚
â”‚  (Events & Experiences)   â”‚               â”‚   (Facts & Concepts)      â”‚
â”‚                           â”‚               â”‚                           â”‚
â”‚  â€¢ "What happened when"   â”‚               â”‚  â€¢ "What is X"            â”‚
â”‚  â€¢ Contextual details     â”‚               â”‚  â€¢ General knowledge      â”‚
â”‚  â€¢ Temporal ordering      â”‚               â”‚  â€¢ Relationships          â”‚
â”‚  â€¢ Emotional tags         â”‚               â”‚  â€¢ Abstract concepts      â”‚
â”‚                           â”‚               â”‚                           â”‚
â”‚  Duration: Days-Weeks     â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚  Duration: Long-term      â”‚
â”‚  Decay: Moderate          â”‚  Abstraction  â”‚  Decay: Very slow         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Decay (Ebbinghaus Curve)

```
Strength
   â”‚
1.0â”œâ”€â”€â”€â”€â—
   â”‚     â•²
   â”‚      â•²
0.8â”œ       â•²
   â”‚        â•²
   â”‚         â•²                    â—† With rehearsal
0.6â”œ          â•²               â—†
   â”‚           â•²          â—†
   â”‚            â•²     â—†
0.4â”œ             â•²â—†
   â”‚              â•²
   â”‚               â•²
0.2â”œ                â•²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Without rehearsal
   â”‚                 â•²
   â”‚                  â•²
0.0â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
   0    1    2    3    4    5    6    7   Time (days)

   Formula: S(t) = Sâ‚€ Ã— e^(-Î»t/importance)
   
   Where:
   â€¢ Sâ‚€ = Initial strength
   â€¢ Î» = Decay rate (configurable)
   â€¢ t = Time since last access
   â€¢ importance = Memory importance score (slows decay)
```

### Conflict Resolution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONFLICT DETECTION & RESOLUTION                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  CONFLICT TYPES                      RESOLUTION STRATEGIES          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Direct          â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚ Recency         â”‚           â”‚
â”‚  â”‚ Contradiction   â”‚                 â”‚ (newest wins)   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Temporal        â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚ Confidence      â”‚           â”‚
â”‚  â”‚ Outdated        â”‚                 â”‚ (highest wins)  â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Source          â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚ Source          â”‚           â”‚
â”‚  â”‚ Disagreement    â”‚                 â”‚ Reliability     â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Preference      â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚ Merge           â”‚           â”‚
â”‚  â”‚ Conflict        â”‚                 â”‚ (combine both)  â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Fact            â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚ User-Guided     â”‚           â”‚
â”‚  â”‚ Inconsistency   â”‚                 â”‚ (ask user)      â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Benchmarks

### Test Configuration

| Parameter | Value |
|-----------|-------|
| Model | Gemma 3 27B (Ollama) |
| Embedding | nomic-embed-text |
| Samples | 15-30 per scenario |
| Runs | 2 per scenario |

### Results

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BENCHMARK RESULTS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚  ACCURACY (Contains Match)                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚                                                                        â”‚
â”‚  Single-hop    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  100%     â”‚
â”‚  Multi-hop     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  100%     â”‚
â”‚  Temporal      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   90%     â”‚
â”‚  Conflict      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   67%     â”‚
â”‚                                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚  LATENCY (p95)                                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                         â”‚
â”‚                                                                        â”‚
â”‚  Single-hop    â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  4.8s               â”‚
â”‚  Multi-hop     â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  9.0s               â”‚
â”‚  Temporal      â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  6.2s               â”‚
â”‚  Conflict      â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  7.9s               â”‚
â”‚                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comparison with Other Systems

| System | Single-hop | Multi-hop | Temporal | Conflict | Notes |
|--------|------------|-----------|----------|----------|-------|
| **LLM Memory** | **100%** | **100%** | **90%** | **67%** | Our system |
| Full History | 100% | 100% | 100% | 100% | Doesn't scale |
| Simple RAG | 70% | 40% | 50% | 30% | No temporal logic |
| Mem0 (reported) | 72.5% | - | - | - | Production system |
| MemGPT | 75% | 60% | - | - | Hierarchical |

### Run Your Own Benchmark

```bash
# Full benchmark suite
python -m benchmarks.benchmark_memory \
    --scenarios single_hop,multi_hop,temporal,conflict \
    --samples 30 \
    --runs 3 \
    --model gemma3:27b

# Quick test
python -m benchmarks.benchmark_memory \
    --scenarios single_hop \
    --samples 10 \
    --runs 1
```

---

## ğŸ“š API Reference

### Core Classes

#### `MemorySystem`

The main orchestrator for all memory operations.

```python
from llm_memory import MemorySystem, MemoryConfig

# Initialize
config = MemoryConfig(
    llm=LLMConfig(provider="ollama", model="gemma3:27b"),
    embedding=EmbeddingConfig(provider="ollama", model="nomic-embed-text"),
)
memory = MemorySystem(config)
await memory.initialize()
await memory.start()

# Store
memory_obj = await memory.remember(
    content="User prefers dark mode",
    user_id="user_123",
    tags=["preference", "ui"],
)

# Retrieve
results = await memory.recall(
    query="What theme does the user prefer?",
    user_id="user_123",
    limit=5,
)

# Stats
stats = memory.get_statistics()
```

#### `RAGPipeline`

Production RAG with LLM synthesis.

```python
from llm_memory.retrieval import RAGPipeline, RAGConfig

config = RAGConfig(
    top_k=10,
    enable_temporal_scoring=True,
    enable_multi_hop=True,
    temporal_weight=0.3,
)

pipeline = RAGPipeline(
    vector_engine=vector_engine,
    embed_func=embedder.embed,
    llm_func=llm.generate,
    config=config,
)

result = await pipeline.answer("What is Alice's job?")
# result.answer = "Alice works at OpenAI as a researcher [1]."
# result.confidence = 0.85
# result.quality = AnswerQuality.HIGH
```

#### `VectorSearchEngine`

ChromaDB-backed vector search.

```python
from llm_memory.retrieval import VectorSearchEngine, VectorSearchConfig

config = VectorSearchConfig(
    collection_name="my_memories",
    hnsw_space="cosine",
    similarity_threshold=0.5,
)

engine = VectorSearchEngine(config)
await engine.initialize()

# Add memories
await engine.add_memory(memory, embedding)

# Search
results = await engine.search(query_embedding, k=10)
# or hybrid search
results = await engine.hybrid_search(query_embedding, query_text, k=10)
```

#### `MultiHopReasoner`

Complex query decomposition and iterative retrieval.

```python
from llm_memory.retrieval import MultiHopReasoner, MultiHopConfig

config = MultiHopConfig(
    max_hops=5,
    min_confidence=0.3,
    memories_per_hop=3,
)

reasoner = MultiHopReasoner(
    retrieve_func=my_retrieve_func,
    llm_func=my_llm_func,
    config=config,
)

path = await reasoner.reason(
    "What is the capital of the country where my friend lives?"
)
# path.hops = [ReasoningHop(...), ...]
# path.final_answer = "Paris"
```

---

## âš™ï¸ Configuration

### Environment Variables

```bash
# LLM Configuration
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_LLM_MODEL=gemma3:27b
DEFAULT_EMBEDDING_MODEL=nomic-embed-text

# Storage
MEMORY_PERSIST_DIR=./memory_data
CHROMA_PERSIST_DIR=./chroma_data

# Memory Settings
MEMORY_DECAY_RATE=0.1
CONSOLIDATION_INTERVAL=300  # seconds
```

### Configuration Options

```python
from llm_memory.config import (
    MemoryConfig,
    LLMConfig,
    EmbeddingConfig,
    StorageConfig,
    DecayConfig,
)

config = MemoryConfig(
    # LLM settings
    llm=LLMConfig(
        provider="ollama",           # ollama, openai, anthropic
        model="gemma3:27b",
        temperature=0.7,
        max_tokens=1000,
    ),
    
    # Embedding settings
    embedding=EmbeddingConfig(
        provider="ollama",
        model="nomic-embed-text",
        dimensions=768,
    ),
    
    # Storage settings
    storage=StorageConfig(
        backend="sqlite",
        path="./memory.db",
    ),
    
    # Decay settings
    decay=DecayConfig(
        function="ebbinghaus",       # ebbinghaus, power_law, linear
        rate=0.1,
        importance_factor=0.5,
    ),
)
```

---

## ğŸ”§ Advanced Usage

### Event Hooks

```python
from llm_memory.api import EventHooks

hooks = EventHooks()

@hooks.on_store
async def log_store(memory):
    print(f"Stored: {memory.id}")

@hooks.on_recall
async def log_recall(query, results):
    print(f"Query: {query}, Found: {len(results)}")

@hooks.on_conflict
async def handle_conflict(old, new, conflict_type):
    print(f"Conflict detected: {conflict_type}")
    return "keep_new"  # Resolution strategy

memory = MemorySystem(config, hooks=hooks)
```

### LangChain Integration

```python
from llm_memory.api.integrations import LLMMemory
from langchain.chains import ConversationChain

# Create LangChain-compatible memory
memory = LLMMemory(
    memory_system=my_memory_system,
    session_id="session_123",
)

# Use in chain
chain = ConversationChain(
    llm=my_llm,
    memory=memory,
)

response = chain.run("What's my name?")
```

### Custom Memory Types

```python
from llm_memory.models import BaseMemory, MemoryType
from pydantic import Field

class TaskMemory(BaseMemory):
    """Custom memory type for tasks."""
    
    memory_type: MemoryType = MemoryType.SEMANTIC
    
    # Custom fields
    priority: int = Field(default=1, ge=1, le=5)
    due_date: datetime | None = None
    status: str = "pending"
    
    def get_summary(self) -> str:
        return f"[P{self.priority}] {self.content} ({self.status})"
```

---

## ğŸ“ Project Structure

```
llm_memory/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ config.py                 # Configuration classes
â”œâ”€â”€ models/                   # Data models
â”‚   â”œâ”€â”€ base.py              # BaseMemory, ImportanceFactors
â”‚   â”œâ”€â”€ short_term.py        # ShortTermMemory, WorkingContext
â”‚   â”œâ”€â”€ episodic.py          # EpisodicMemory, Episode
â”‚   â””â”€â”€ semantic.py          # SemanticMemory, Fact, Concept
â”œâ”€â”€ storage/                  # Storage backends
â”‚   â”œâ”€â”€ base.py              # Abstract base
â”‚   â”œâ”€â”€ sqlite.py            # SQLite implementation
â”‚   â””â”€â”€ vector.py            # ChromaDB wrapper
â”œâ”€â”€ encoding/                 # Memory encoding
â”‚   â”œâ”€â”€ embedder.py          # Embedding generation
â”‚   â””â”€â”€ summarizer.py        # LLM summarization
â”œâ”€â”€ decay/                    # Memory decay
â”‚   â”œâ”€â”€ functions.py         # Decay algorithms
â”‚   â””â”€â”€ scheduler.py         # Background decay
â”œâ”€â”€ consolidation/            # Memory consolidation
â”‚   â”œâ”€â”€ pipeline.py          # Consolidation logic
â”‚   â””â”€â”€ merger.py            # Memory merging
â”œâ”€â”€ conflict/                 # Conflict resolution
â”‚   â”œâ”€â”€ detector.py          # Conflict detection
â”‚   â””â”€â”€ resolver.py          # Resolution strategies
â”œâ”€â”€ retrieval/                # Memory retrieval
â”‚   â”œâ”€â”€ intent.py            # Intent classification
â”‚   â”œâ”€â”€ searcher.py          # Memory search
â”‚   â”œâ”€â”€ ranker.py            # Result ranking
â”‚   â”œâ”€â”€ vector_search.py     # ChromaDB search
â”‚   â”œâ”€â”€ temporal.py          # Time-aware scoring
â”‚   â”œâ”€â”€ multi_hop.py         # Multi-hop reasoning
â”‚   â””â”€â”€ rag_pipeline.py      # Full RAG pipeline
â”œâ”€â”€ api/                      # External APIs
â”‚   â”œâ”€â”€ memory_api.py        # Programmatic API
â”‚   â”œâ”€â”€ memory_system.py     # Main orchestrator
â”‚   â”œâ”€â”€ hooks.py             # Event hooks
â”‚   â””â”€â”€ integrations/        # Third-party integrations
â”‚       â””â”€â”€ langchain.py
â””â”€â”€ agent/                    # Agent implementations
    â”œâ”€â”€ cli.py               # CLI interface
    â”œâ”€â”€ web_ui.py            # Gradio UI
    â”œâ”€â”€ memory_agent.py      # LangGraph agent
    â””â”€â”€ tools.py             # Agent tools

benchmarks/                   # Benchmarking suite
â”œâ”€â”€ benchmark_memory.py      # Main benchmark script
â”œâ”€â”€ scenarios.py             # Test scenarios
â”œâ”€â”€ metrics.py               # Evaluation metrics
â”œâ”€â”€ runner.py                # Benchmark runner
â””â”€â”€ reports/                 # Generated reports
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

```bash
# Fork and clone
git clone https://github.com/YOUR_USERNAME/LLM_Memory.git
cd LLM_Memory

# Create branch
git checkout -b feature/your-feature

# Install dev dependencies
pip install -e ".[dev]"

# Run tests
pytest tests/ -v --cov=llm_memory

# Run linting
ruff check llm_memory/
black llm_memory/

# Submit PR
git push origin feature/your-feature
```

### Development Guidelines

1. **Tests**: Add tests for new features
2. **Types**: Use type hints
3. **Docs**: Update docstrings and README
4. **Style**: Follow black + ruff formatting

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

This project builds upon research from:

- **MemoryAgentBench** - Evaluation framework
- **Mem0** - Production memory patterns
- **MemGPT** - Hierarchical memory concepts
- **TiMem** - Temporal memory reasoning
- **Soar** - Cognitive architecture inspiration

---

<div align="center">

**[â¬† Back to Top](#-llm-memory)**

Made with â¤ï¸ by the LLM Memory Team

</div>
